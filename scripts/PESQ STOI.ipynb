{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746e8193",
   "metadata": {},
   "source": [
    "### Caution) We recommend to use GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0dd4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import sys\n",
    "import concurrent\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "import scipy.stats as st\n",
    "\n",
    "os.environ[\"MKL_NUM_THREADS\"]='1'\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]='1'\n",
    "os.environ[\"OMP_NUM_THREADS\"]='1'\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchaudio.transforms import Resample\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "sys.path.insert(0, \"../\")\n",
    "from utils import get_hparams\n",
    "from models import get_wrapper\n",
    "from functional import stft, spec_to_mel\n",
    "from utils.data import get_dataset_dataloader\n",
    "from utils.data.audio import Dataset, collate\n",
    "from utils import HParams\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'\n",
    "device = 'cuda'     # 'cpu' or 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05375ab6",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f95168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint file '../logs/encodec_disc_ablation/grad_none_1/00050.pth'...\n",
      "#params: 9.577019 M\n",
      "Decoder #params: 6.587246 M\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"../logs/hil_audio\"\n",
    "hps = get_hparams(f\"{base_dir}/config.yaml\", base_dir)\n",
    "wrapper = get_wrapper(hps.model)(hps, device=device)\n",
    "wrapper.load()\n",
    "wrapper.eval()\n",
    "\n",
    "sr = hps.data.sampling_rate\n",
    "hop_size = wrapper.hop_size\n",
    "\n",
    "lookahead = getattr(hps.train, \"delay\", getattr(hps.train, \"lookahead\", 0))\n",
    "hps.data.filelists[\"infer\"] = f'../{hps.data.filelists[\"infer\"]}'\n",
    "\n",
    "n_params = 0\n",
    "for n, p in wrapper.model.named_parameters():\n",
    "    n_params += p.numel()\n",
    "print(f\"#params: {n_params/1000_000} M\")\n",
    "n_params = 0\n",
    "for n, p in wrapper.model.decoder.named_parameters():\n",
    "    n_params += p.numel()\n",
    "print(f\"Decoder #params: {n_params/1000_000} M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7b5fcf",
   "metadata": {},
   "source": [
    "# Speech Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eedcd716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pesq dataset filtered: 587/587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "data_sr = 48_000\n",
    "hp = HParams(**dict(\n",
    "    data=dict(\n",
    "        dataset=\"Dataset\",\n",
    "        wav_dir=\"/home/shahn/Datasets/VCTK-Corpus/wav48\",\n",
    "        data_dir = \"\",\n",
    "        extension=\"\",\n",
    "        filelists=dict(\n",
    "            pesq=\"/home/shahn/Documents/trainer/filelists/etc/VCTK_valid.txt\"\n",
    "        ),\n",
    "        filter=dict(\n",
    "            pesq=True\n",
    "        ),\n",
    "        normalize_method=None,\n",
    "        channel=1,\n",
    "        sampling_rate=data_sr,\n",
    "    ),\n",
    "    train=dict(),\n",
    "    pesq=dict(\n",
    "        batch_size=20,\n",
    "        num_workers=0,\n",
    "    )\n",
    "))\n",
    "resampler48khz = Resample(sr, 48000).to(device)\n",
    "resampler16khz = Resample(sr, 16000).to(device)\n",
    "resampler10khz = Resample(sr, 10000).to(device)\n",
    "dataset, dataloader = get_dataset_dataloader(hp, mode=\"pesq\", keys=[\"wav\", \"wav_len\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ad3837",
   "metadata": {},
   "source": [
    "# Audio Dataset (Choose b/w Speech and Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39dc43b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pesq dataset filtered: 300/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "hp = HParams(**dict(\n",
    "    data=dict(\n",
    "        dataset=\"Dataset\",\n",
    "        wav_dir=\"/home/shahn/Datasets\",\n",
    "        data_dir = \"\",\n",
    "        extension=\"\",\n",
    "        filelists=dict(\n",
    "            pesq=\"/home/shahn/Documents/trainer/filelists/DNS/DNS_VCTK_jamendo_pesq_24khz.txt\"\n",
    "        ),\n",
    "        filter=dict(\n",
    "            pesq=True\n",
    "        ),\n",
    "        normalize_method=None,\n",
    "        channel=1,\n",
    "        sampling_rate=sr,\n",
    "    ),\n",
    "    train=dict(),\n",
    "    pesq=dict(\n",
    "        batch_size=5,\n",
    "        num_workers=0,\n",
    "    )\n",
    "))\n",
    "resampler48khz = Resample(sr, 48000).to(device)\n",
    "resampler16khz = Resample(sr, 16000).to(device)\n",
    "resampler10khz = Resample(sr, 10000).to(device)\n",
    "dataset, dataloader = get_dataset_dataloader(hp, mode=\"pesq\", keys=[\"wav\", \"wav_len\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe588aeb",
   "metadata": {},
   "source": [
    "# Calculate Metrics using Multi Processing (Fast, but may crash your server!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3039f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pesq import pesq\n",
    "from pystoi import stoi\n",
    "from utils.measure_visqol import measure_visqol\n",
    "\n",
    "\n",
    "SAMPLING_RATE = {\n",
    "    \"pesq\": 16_000,\n",
    "    \"stoi\": 10_000,\n",
    "    \"visqol\": 16_000,\n",
    "    \"visqol_audio\": 48_000,\n",
    "}\n",
    "\n",
    "def metric(ref, deg, wav_len, mode, idx=0) -> int:\n",
    "    mode = mode.lower()\n",
    "    mode_sr = SAMPLING_RATE[mode]\n",
    "    wav_len = int(wav_len * mode_sr / sr)\n",
    "    ref = ref[:wav_len]\n",
    "    deg = deg[:wav_len]\n",
    "    if mode == \"pesq\":\n",
    "        return pesq(16000, ref, deg, \"wb\")\n",
    "    elif mode == \"pystoi\" or mode == \"stoi\":\n",
    "        return stoi(ref, deg, 10000)\n",
    "    elif mode == \"visqol\":\n",
    "        return measure_visqol(ref, deg, idx, \"speech\")\n",
    "    elif mode == \"visqol_audio\":\n",
    "        return measure_visqol(ref, deg, idx, \"audio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcd22fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PESQ:   0%|                                                               | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e57aa6d48b64253aeed5739248669d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "visqol_audio:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 4   # number of quantizers in the RVQ\n",
    "pesq_list, stoi_list, visqol_list, va_list = [], [], [], []\n",
    "max_items = 0\n",
    "pesq_futures, visqol_futures, va_futures = [], [], []\n",
    "\n",
    "calc_pesq, calc_stoi, calc_visqol, calc_va = False, False, False, True\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=32) as executor:\n",
    "    for batch in tqdm(dataloader, desc=\"PESQ\", leave=False, dynamic_ncols=True):\n",
    "        wav_r = batch[\"wav\"].to(device).unsqueeze(1)\n",
    "        wav_lens = batch[\"wav_len\"]\n",
    "        batch_size = wav_r.size(0)\n",
    "\n",
    "        batch_wav_len = wav_r.size(-1) // hop_size * hop_size\n",
    "        wav_r = wav_r[..., :batch_wav_len]\n",
    "        with torch.no_grad():\n",
    "            wav_g, *_ = wrapper.model(wav_r, n=N)\n",
    "            if lookahead > 0:\n",
    "                wav_r = wav_r[..., :-lookahead]\n",
    "                wav_g = wav_g[..., lookahead:]\n",
    "        \n",
    "        if calc_pesq or calc_visqol:\n",
    "            wav_r_pesq = resampler16khz(wav_r).cpu().numpy()\n",
    "            wav_g_pesq = resampler16khz(wav_g).cpu().numpy()\n",
    "        if calc_stoi:\n",
    "            wav_r_stoi = resampler10khz(wav_r).cpu().numpy()\n",
    "            wav_g_stoi = resampler10khz(wav_g).cpu().numpy()\n",
    "        if calc_va:\n",
    "            wav_r_va = resampler48khz(wav_r).cpu().numpy()\n",
    "            wav_g_va = resampler48khz(wav_g).cpu().numpy()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            file_idx = max_items + i\n",
    "            if calc_pesq:\n",
    "                pesq_futures.append(executor.submit(metric, wav_r_pesq[i, 0], wav_g_pesq[i, 0], wav_lens[i], \"pesq\"))\n",
    "            if calc_visqol:\n",
    "                visqol_futures.append(executor.submit(metric, wav_r_pesq[i, 0], wav_g_pesq[i, 0], wav_lens[i], \"visqol\", file_idx))\n",
    "            if calc_stoi:\n",
    "                stoi_list.append(metric(wav_r_stoi[i, 0], wav_g_stoi[i, 0], wav_lens[i], \"stoi\"))\n",
    "            if calc_va:\n",
    "                va_futures.append(executor.submit(metric, wav_r_va[i, 0], wav_g_va[i, 0], wav_lens[i], \"visqol_audio\", file_idx))\n",
    "        max_items += batch_size\n",
    "    \n",
    "    if calc_pesq:\n",
    "        for idx, future in tqdm(\n",
    "            enumerate(concurrent.futures.as_completed(pesq_futures), start=1),\n",
    "            desc='pesq', total=max_items, leave=False\n",
    "        ):\n",
    "            pesq_list.append(future.result())\n",
    "    if calc_visqol:\n",
    "        for idx, future in tqdm(\n",
    "            enumerate(concurrent.futures.as_completed(visqol_futures), start=1),\n",
    "            desc='visqol', total=max_items, leave=False\n",
    "        ):\n",
    "            visqol_list.append(future.result())\n",
    "    if calc_va:\n",
    "        for idx, future in tqdm(\n",
    "            enumerate(concurrent.futures.as_completed(va_futures), start=1),\n",
    "            desc='visqol_audio', total=max_items, leave=False\n",
    "        ):\n",
    "            va_list.append(future.result())\n",
    "\n",
    "if calc_pesq:\n",
    "    pesq_mean = sum(pesq_list) / max_items\n",
    "    pesq_ci = pesq_mean - st.t.interval(confidence=0.95, df=len(pesq_list)-1, loc=pesq_mean, scale=st.sem(pesq_list))[0]\n",
    "    print(f\"\\rPESQ: {pesq_mean} +- {pesq_ci}\", flush=True)\n",
    "if calc_stoi:\n",
    "    stoi_mean = sum(stoi_list) / max_items\n",
    "    stoi_ci = stoi_mean - st.t.interval(confidence=0.95, df=len(stoi_list)-1, loc=stoi_mean, scale=st.sem(stoi_list))[0]\n",
    "    print(f\"\\rSTOI: {stoi_mean} +- {stoi_ci}\", flush=True)\n",
    "if calc_visqol:\n",
    "    visqol_mean = sum(visqol_list) / max_items\n",
    "    visqol_ci = visqol_mean - st.t.interval(confidence=0.95, df=len(visqol_list)-1, loc=visqol_mean, scale=st.sem(visqol_list))[0]\n",
    "    print(f\"\\rViSQOL: {visqol_mean} +- {visqol_ci}\", flush=True)\n",
    "if calc_va:\n",
    "    va_mean = sum(va_list) / max_items\n",
    "    va_ci = va_mean - st.t.interval(confidence=0.95, df=len(va_list)-1, loc=va_mean, scale=st.sem(va_list))[0]\n",
    "    print(f\"ViSQOL Audio: {va_mean} +- {va_ci}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c845a",
   "metadata": {},
   "source": [
    "# Calculate Metrics using Single Process (Very slow, but we didn't experienced any crash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b962e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint file '../logs/encodec_disc_ablation/grad_none_1/00050.pth'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PESQ:   0%|                                                             | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_none_1: 4.148787836073998 +- 0.021267010126748254\n"
     ]
    }
   ],
   "source": [
    "N = 4\n",
    "for name in [\"grad_none_1\"]:\n",
    "    base_dir = f\"../logs/encodec_disc_ablation/{name}\"\n",
    "    hps = get_hparams(f\"{base_dir}/config.yaml\", base_dir)\n",
    "    if getattr(hps.model_kwargs, \"act_norm\", None) == \"SyncBatchNorm\":\n",
    "        hps.model_kwargs.act_norm = \"BatchNorm1d\"\n",
    "    wrapper = get_wrapper(hps.model)(hps, device=device)\n",
    "    wrapper.load()\n",
    "    wrapper.eval()\n",
    "    \n",
    "    va_list = []\n",
    "    max_items = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"PESQ\", leave=False, dynamic_ncols=True):\n",
    "        wav_r = batch[\"wav\"].to(device).unsqueeze(1)\n",
    "        wav_lens = batch[\"wav_len\"]\n",
    "        batch_size = wav_r.size(0)\n",
    "\n",
    "        batch_wav_len = wav_r.size(-1) // hop_size * hop_size\n",
    "        wav_r = wav_r[..., :batch_wav_len]\n",
    "        with torch.no_grad():\n",
    "            wav_g, *_ = wrapper.model(wav_r, n=N)\n",
    "            if lookahead > 0:\n",
    "                wav_r = wav_r[..., :-lookahead]\n",
    "                wav_g = wav_g[..., lookahead:]\n",
    "\n",
    "        wav_r_va = resampler48khz(wav_r).cpu().numpy()\n",
    "        wav_g_va = resampler48khz(wav_g).cpu().numpy()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            file_idx = max_items + i\n",
    "            va_list.append(metric(wav_r_va[i, 0], wav_g_va[i, 0], wav_lens[i], \"visqol_audio\", file_idx))\n",
    "        max_items += batch_size\n",
    "\n",
    "    va_mean = sum(va_list) / max_items\n",
    "    va_ci = va_mean - st.t.interval(confidence=0.95, df=len(va_list)-1, loc=va_mean, scale=st.sem(va_list))[0]\n",
    "    print(f\"{name}: {va_mean} +- {va_ci}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee01744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
